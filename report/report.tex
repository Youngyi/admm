
\title{Deep Learning Project 3}
\author{
        Group 2\\
        Hong Kong University of Science and Technology
}
\date{\today}

\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{cite}
\begin{document}
\maketitle

\begin{abstract}
In this project we have implemented ADMM optimization methods for the convolution layers.
For the convolution layers, we considered converting a convoluted matrix into a dense toeplitz matrix.
The weights updates of kernels are done by solving a system of equations by sampling equations obtained from Toeplitz matrix.
We found that our method worked faster than author's implementation since they only considered the pseudoinverse of the matrix.
We used MNIST digit dataset (odd-even classification) and found that our method gives 90.6\% over traditional backprop method 79.6\%.
\end{abstract}

\section{Introduction}
ADMM (Alternating Direction Method of Multipliers) is the divide and conquer approach to solve a convex optimization problem.
For this project, we have implemented ADMM for Neural Networks.

\section{Weight Update}

For each layer $l$, the optimal solution would minimize $||z_l - W_l a_{l-1} ||^2$.
The authors approached this problem by taking the pseudoinverse of $a_{l-1}$, which is $a_{l-1}^*$.
In our opinion, taking pseudoinverse of a very tall matrix (in this case Toeplitz matrix of $a_{l-1}$) is an overkill and inaccurate.
Hence, we approach this problem in a different manner.

Firstly, 

\bibliographystyle{apalike}
\bibliography{ref}
\end{document}
